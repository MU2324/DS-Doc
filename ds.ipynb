{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ks5_qogSuJEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Reading data from CSV and JSON files into a data frame:\n",
        "#1)\tReading CSV:\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "data = pd.read_csv('iris.csv')\n",
        "print(data)\n",
        "\n",
        "#2)\tReading JSON:\n",
        "import pandas as pd\n",
        "data = pd.read_json('iris.json')\n",
        "print(data)\n",
        "\n",
        "\n",
        "# Handling missing values and outliers:\n",
        "# 1)\tUsing fillna():\n",
        "import pandas as pd\n",
        "data = pd.read_csv('titanic.csv')\n",
        "print(data)\n",
        "updatedData = data.fillna(value=0)\n",
        "print(updatedData)\n",
        "\n",
        "\n",
        "# 2)\tUsing dropna():\n",
        "import pandas as pd\n",
        "csvFile = pd.read_csv(\"titanic.csv\")\n",
        "print(csvFile)\n",
        "updatedcsvFile = csvFile.dropna()\n",
        "print(updatedcsvFile)\n",
        "\n",
        "\n",
        "# Manipulate and transform data using functions:\n",
        "# 1)\tFiltering:\n",
        "import pandas as pd\n",
        "data = pd.read_csv('titanic.csv')\n",
        "survived = data[data['Survived'] == 1] # Filtering data for survived\n",
        "print(survived)\n",
        "\n",
        "# 2)\tSorting:\n",
        "import pandas as pd\n",
        "csvFile = pd.read_csv(\"titanic.csv\")\n",
        "print(csvFile)\n",
        "ageSorted = csvFile.sort_values(by=['Age'])\n",
        "print(ageSorted)\n",
        "\n",
        "\n",
        "# 3)\tGrouping:\n",
        "import pandas as pd\n",
        "csvFile = pd.read_csv(\"titanic.csv\")\n",
        "print(csvFile)\n",
        "groupedbyEmbarked = csvFile.groupby([\"Survived\"]).mean([\"Pclass\",\"Sex\", \"Age\"])  #Grouping by survival status and calculating\n",
        "print(groupedbyEmbarked)\n"
      ],
      "metadata": {
        "id": "Vfvl8UbquKOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Feature Scaling\n",
        "\n",
        "#1)\tNormalization:\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('salary.csv')\n",
        "print(\"Normalization\")\n",
        "mmscaler  = MinMaxScaler()\n",
        "norm = mmscaler.fit_transform(data)\n",
        "print(norm)\n",
        "\n",
        "\n",
        "#2)\tStandardization:\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Standardization\")\n",
        "stdscaler = StandardScaler()\n",
        "std = stdscaler.fit_transform(data)\n",
        "print(std)\n",
        "\n",
        "\n",
        "# Dummification:\n",
        "# 1)\tLabelBinalizer:\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "data = pd.read_csv('weather.csv')\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "lb_result = lb.fit_transform(df['Outlook'])\n",
        "binalizerdf = pd.DataFrame(lb_result, columns=sorted(list(set(df['Outlook']))))\n",
        "print(binalizerdf)\n",
        "\n",
        "\n",
        "# 2)\tBinaryEncoder:\n",
        "#from category_encoders import BinaryEncoder\n",
        "\n",
        "#print(\"Using BinaryEncoder\")\n",
        "#bncoder = BinaryEncoder()\n",
        "#bncoder.fit(df['Outlook'])\n",
        "#binalizerdf = pd.DataFrame(bncoder.transform(df['Outlook']),columns=sorted(list(set(df['Outlook']))))\n",
        "#print(binalizerdf)\n",
        "\n",
        "#OR\n",
        "!pip install category_encoders\n",
        "from category_encoders import BinaryEncoder\n",
        "# Create a sample dataframe\n",
        "data = {'color': ['red', 'green', 'blue', 'red', 'green', 'blue']}\n",
        "df = pd.DataFrame(data)\n",
        "# Create a BinaryEncoder object\n",
        "encoder = BinaryEncoder()\n",
        "# Fit the encoder to the data\n",
        "encoder.fit(df['color'])\n",
        "# Transform the data\n",
        "encoded_data = encoder.transform(df['color'])\n",
        "# Print the encoded data\n",
        "print(encoded_data)\n",
        "\n",
        "#3)\tGet Dummies:\n",
        "import pandas as pd\n",
        "gt = pd.get_dummies(df, columns=['color'])\n",
        "gt1 = pd.get_dummies(df, columns=['Temperature'])\n",
        "gt2 = pd.get_dummies(df, columns=['Humidity'])\n",
        "gt3 = pd.get_dummies(df, columns=['Windy'])\n",
        "\n",
        "final_df = pd.concat([gt, gt1, gt2, gt3])\n",
        "print(final_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "2B66Aqj2uM1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3R Dummification\n",
        "!pip install category_encoders\n",
        "import pandas as pd\n",
        "from category_encoders import BinaryEncoder\n",
        "# Create a sample dataframe\n",
        "data = {'color': ['red', 'green', 'blue', 'red', 'green', 'blue']}\n",
        "df = pd.DataFrame(data)\n",
        "# Create a BinaryEncoder object\n",
        "encoder = BinaryEncoder()\n",
        "# Fit the encoder to the data\n",
        "encoder.fit(df['color'])\n",
        "# Transform the data\n",
        "encoded_data = encoder.transform(df['color'])\n",
        "# Print the encoded data\n",
        "print(encoded_data)\n"
      ],
      "metadata": {
        "id": "uamoxmxpiQy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4R Hypothesis Testing (T-test)\n",
        "INPUT\n",
        "\n",
        "test1<-c(20,30,50,40,30,20,50,40,30)\n",
        "test2<-c(30,40,60,50,40,30,60,50,40)\n",
        "t.test(test1,test2,alternative=\"two.sided\",var.equal=FALSE)\n",
        "\n",
        "OUTPUT\n",
        "\n",
        "Welch Two Sample t-test\n",
        "data:  test1 and test2\n",
        "t = -1.8766, df = 16, p-value = 0.07893\n",
        "alternative hypothesis: true difference in means is not equal to 0\n",
        "95 percent confidence interval:\n",
        "-21.296343   1.296343\n",
        "sample estimates:\n",
        "mean of x mean of y\n",
        "34.44444  44.44444\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "INPUT\n",
        "\n",
        "test1<-c(30,40,60,50,40,30,60,50,40)\n",
        "test2<-c(20,30,50,40,30,20,50,40,30)\n",
        "t.test(test1,test2,alternative=\"two.sided\",var.equal=FALSE)\n",
        "\n",
        "OUTPUT\n",
        "\n",
        "Welch Two Sample t-test\n",
        "data:  test1 and test2\n",
        "t = 1.8766, df = 16, p-value = 0.07893\n",
        "alternative hypothesis: true difference in means is not equal to 0\n",
        "95 percent confidence interval:\n",
        "-1.296343 21.296343\n",
        "sample estimates:\n",
        "mean of x mean of y\n",
        "44.44444  34.44444\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Chi-square test and T test\n",
        "Import dataset survey\n",
        "\n",
        "library(MASS)\n",
        "survey\n",
        "\n",
        "\n",
        "\n",
        "Choose only two column and print them\n",
        "\n",
        "sample<-data.frame(survey$Smoke,survey$Exer)\n",
        "sample\n",
        "\n",
        "\n",
        "\n",
        "Create contigency table and print them\n",
        "\n",
        "Stable<-table(survey$Smoke,survey$Exer)\n",
        "Stable\n",
        "\n",
        "Freq      None      Some\n",
        "Heavy      7           1             3\n",
        "Never      87         18           84\n",
        "Occas      12          3             4\n",
        "Regul       9           1             7\n",
        "\n",
        "\n",
        "Result(chisq.test function)\n",
        "\n",
        "result<-chisq.test(Stable)\n",
        "result\n",
        "\n",
        "Pearson's Chi-squared test\n",
        "\n",
        "data:  Stable\n",
        "X-squared = 5.4885, df = 6, p-value = 0.4828\n",
        "\n",
        "\n",
        "\n",
        "resultT<-t.test(Stable)\n",
        "resultT\n",
        "\n",
        "\n",
        "One Sample t-test\n",
        "\n",
        "data:  Stable\n",
        "t = 2.1878, df = 11, p-value = 0.05117\n",
        "alternative hypothesis: true mean is not equal to 0\n",
        "95 percent confidence interval:\n",
        "-0.1187186 39.4520519\n",
        "sample estimates:\n",
        "mean of x\n",
        "19.66667\n",
        "\n",
        "\n",
        "\n",
        "If p-value >0.05 then Null hypothesis Accept and alternative Rejected mean No relation\n",
        "\n",
        "If p-value<0.05 then Null hypothesis Reject and alternative Accept means\n",
        "Have relation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LKz5R3YUuKVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5R Load the CSV file:\n",
        "data <-read.csv(\"E:\\\\TYCS\\\\DataScience\\\\Political_Interest.csv\")\n",
        "attach(data)\n",
        "\n",
        "Plot the boxplot:\n",
        "boxplot(PoliticalInterest~Gender)\n",
        "\n",
        "\n",
        "Generate summary:\n",
        "result = aov(PoliticalInterest~Gender)\n",
        "summary(result)\n",
        "\n",
        "\n",
        "Plot the boxplot:\n",
        "boxplot(PoliticalInterest~Gender+EconomicalCondition)\n",
        "\n",
        "\n",
        "Generate summary:\n",
        "result = aov(PoliticalInterest~Gender+EconomicalCondition)\n",
        "summary(result)\n"
      ],
      "metadata": {
        "id": "MO5xP26xuLLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqFQ5uU4tHwg"
      },
      "outputs": [],
      "source": [
        "#6 Regression and Its Types\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=np.array([26,28,32,35,39]).reshape((-1,1))\n",
        "y=np.array([123,245,296,389,435])\n",
        "print(x)\n",
        "print(y)\n",
        "model=LinearRegression()\n",
        "model.fit(x,y)\n",
        "\n",
        "y_pred=model.predict(x)\n",
        "print(\"Predicted responce is\",y_pred)\n",
        "\n",
        "y_new=model.predict(x)\n",
        "y_new\n",
        "x_new=np.array([40]).reshape((-1,1))\n",
        "y_new=model.predict(x_new)\n",
        "y_new\n",
        "print(\"predicted outcome is \",y_new)\n",
        "plt.scatter(x, y)\n",
        "plt.plot(x, y_pred)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7R data <- read.csv(\"E:\\\\ TYCS\\\\Data Science\\\\logistic regression\\\\diabetes.csv\",head=TRUE,sep=\",\")\n",
        "> library(caTools)\n",
        "> split <- sample.split(data,SplitRatio=0.8)\n",
        "> split\n",
        "[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n",
        "> training <- subset(data , split==\"TRUE\")\n",
        "> testing <- subset(data , split==\"FALSE\")\n",
        "> model <- glm(outcome~.,training,family=\"binomial\")\n",
        "> summary(model)\n",
        "> res <- predict(model,training,type=\"response\")\n",
        "> res\n",
        "> (table(ActualValue=training$outcome,PredictedValue=res>0.3))\n",
        "Calculating the accuracy\n",
        "> (297+156)/(297+99+45+156)\n",
        "> library(ROCR)\n",
        "> ROCRpred = prediction(res, training$outcome)\n",
        "> ROCRpref = performance(ROCRpred,\"tpr\" , \"fpr\")\n",
        "> plot(ROCRpref,colorize=TRUE,print.cuttofs.at=seq(0.1,by=0.5))\n"
      ],
      "metadata": {
        "id": "LaqAze_ruLRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8R Practical no 8\n",
        "#K-Means Clustering\n",
        "\n",
        "#Apply the K-Means algorithm to group similar data points into clusters.\n",
        "\n",
        "# Loading data\n",
        "data(iris)\n",
        "\n",
        "# Structure\n",
        "str(iris)\n",
        "\n",
        "# Installing Packages\n",
        "install.packages(\"ClusterR\")\n",
        "install.packages(\"cluster\")\n",
        "\n",
        "# Loading package\n",
        "library(ClusterR)\n",
        "library(cluster)\n",
        "\n",
        "iris_1 <- iris[, -5]\n",
        "\n",
        "# Fitting K-Means clustering Model\n",
        "# to training dataset\n",
        "set.seed(240) # Setting seed\n",
        "kmeans.re <- kmeans(iris_1, centers = 3, nstart = 20)\n",
        "kmeans.re\n",
        "\n",
        "# each observation\n",
        "kmeans.re$cluster\n",
        "\n",
        "# Confusion Matrix\n",
        "cm <- table(iris$Species, kmeans.re$cluster)\n",
        "cm\n",
        "\n",
        "plot(iris_1[c(\"Sepal.Length\", \"Sepal.Width\")])\n",
        "plot(iris_1[c(\"Sepal.Length\", \"Sepal.Width\")],\n",
        "     col = kmeans.re$cluster)\n",
        "plot(iris_1[c(\"Sepal.Length\", \"Sepal.Width\")],\n",
        "     col = kmeans.re$cluster,\n",
        "     main = \"K-means with 3 clusters\")\n",
        "\n",
        "\n",
        "## Plotiing cluster centers\n",
        "kmeans.re$centers\n",
        "kmeans.re$centers[, c(\"Sepal.Length\", \"Sepal.Width\")]\n",
        "\n",
        "# cex is font size, pch is symbol\n",
        "points(kmeans.re$centers[, c(\"Sepal.Length\", \"Sepal.Width\")],\n",
        "       col = 1:3, pch = 8, cex = 3)\n",
        "\n",
        "## Visualizing clusters\n",
        "y_kmeans <- kmeans.re$cluster\n",
        "clusplot(iris_1[, c(\"Sepal.Length\", \"Sepal.Width\")],\n",
        "         y_kmeans,\n",
        "         lines = 0,\n",
        "         shade = TRUE,\n",
        "         color = TRUE,\n",
        "         labels = 2,\n",
        "         plotchar = FALSE,\n",
        "         span = TRUE,\n",
        "         main = paste(\"Cluster iris\"),\n",
        "         xlab = 'Sepal.Length',\n",
        "         ylab = 'Sepal.Width')\n",
        "\n",
        "\n",
        "#Determine the optimal number of clusters using elbow method or silhouette analysis\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#Load the Dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "#Find optimum number of cluster using Elbow method\n",
        "sse = [] #SUM OF SQUARED ERROR\n",
        "for k in range(1,11):\n",
        "    km = KMeans(n_clusters=k, random_state=2)\n",
        "    km.fit(X)\n",
        "    sse.append(km.inertia_)\n",
        "\n",
        "#Plot the Elbow graph to find the optimum number of cluster\n",
        "sns.set_style(\"whitegrid\")\n",
        "g=sns.lineplot(x=range(1,11), y=sse)\n",
        "\n",
        "g.set(xlabel =\"Number of cluster (k)\",\n",
        "      ylabel = \"Sum Squared Error\",\n",
        "      title ='Elbow Method')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#Build the Kmeans clustering model\n",
        "kmeans = KMeans(n_clusters = 3, random_state = 2)\n",
        "kmeans.fit(X)\n",
        "\n",
        "#Find the cluster center\n",
        "print(kmeans.cluster_centers_)\n",
        "\n",
        "#Predict the cluster group:\n",
        "pred = kmeans.fit_predict(X)\n",
        "print(pred)\n",
        "\n",
        "#Plot the cluster center with data points\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(X[:,0],X[:,1],c = pred, cmap=cm.Accent)\n",
        "plt.grid(True)\n",
        "for center in kmeans.cluster_centers_:\n",
        "    center = center[:2]\n",
        "    plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
        "plt.xlabel(\"petal length (cm)\")\n",
        "plt.ylabel(\"petal width (cm)\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(X[:,2],X[:,3],c = pred, cmap=cm.Accent)\n",
        "plt.grid(True)\n",
        "for center in kmeans.cluster_centers_:\n",
        "    center = center[2:4]\n",
        "    plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
        "plt.xlabel(\"sepal length (cm)\")\n",
        "plt.ylabel(\"sepal width (cm)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"End....\")\n"
      ],
      "metadata": {
        "id": "K8JZZnbhKEI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9R Principal Component Analysis (PCA)\n",
        "\n",
        "#Performing PCA on iris dataset\n",
        "#Load iris dataset\n",
        "iris\n",
        "\n",
        "\n",
        "#load first 4 column of iris Dataset  and print it\n",
        "data <- iris[1:4]\n",
        "data\n",
        "\n",
        "\n",
        "#Using princomp function for performing PCA\n",
        "pc <-princomp(data,cor=TRUE,score=TRUE)\n",
        "pc\n",
        "\n",
        "\n",
        "#Print Summary\n",
        "summary(pc)\n",
        "\n",
        "\n",
        "# Plot Graphically\n",
        "plot(pc)\n",
        "\n",
        "plot(pc,type='l')\n",
        "\n",
        "biplot(pc)\n",
        "\n"
      ],
      "metadata": {
        "id": "POs9dyhsKF-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10 Data Visualization and Storytelling\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "data = {\n",
        "    '3331375': [80, 70, 75, 50, 85],\n",
        "    '3331376': [75, 65, 87, 92, 54],\n",
        "    '3331377': [90, 65, 75, 63, 85],\n",
        "    '3331378': [59, 68, 75, 92, 85],\n",
        "    '3331379': [85, 82, 88, 83, 87],\n",
        "    '3331380': [65, 75, 73, 65, 78],\n",
        "    '3331381': [88, 78, 98, 87, 52],\n",
        "    '3331382': [54, 25, 65, 58, 45],\n",
        "    '3331383': [86, 86, 75, 95, 75],\n",
        "    '3331384': [85, 87, 64, 78, 96],\n",
        "    '3331385': [85, 69, 78, 71, 70],\n",
        "    '3331386': [98, 85, 84, 87, 76],\n",
        "    '3331387': [85, 68, 78, 89, 87],\n",
        "    '3331388': [58, 86, 47, 58, 78],\n",
        "    '3331389': [58, 86, 65, 78, 98],\n",
        "    '3331390': [75, 59, 45, 56, 85],\n",
        "    '3331391': [95, 65, 75, 84, 98],\n",
        "    '3331392': [68, 65, 67, 62, 75],\n",
        "    '3331393': [98, 95, 97, 96, 94],\n",
        "    '3331394': [45, 65, 54, 55, 45],\n",
        "    '3331395': [98, 85, 86, 81, 80],\n",
        "    '3331396': [78, 73, 74, 75, 74],\n",
        "    '3331397': [90, 85, 92, 68, 76],\n",
        "    '3331398': [65, 67, 62, 78, 76],\n",
        "    '3331399': [50, 55, 64, 60, 78]\n",
        "}\n",
        "averages = []\n",
        "for student, marks in data.items():\n",
        "    average = sum(marks) / len(marks)\n",
        "    averages.append(average)\n",
        "    #print(f\"Average marks for {student}: {average}\")\n",
        "mean = statistics.mean(averages)\n",
        "mode = statistics.mode(averages)\n",
        "median = statistics.median(averages)\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Mode: {mode}\")\n",
        "print(f\"Median: {median}\")\n",
        "# Visualize data in a bar graph\n",
        "students = list(data.keys())\n",
        "plt.bar(students, averages)\n",
        "plt.xlabel('Student')\n",
        "plt.ylabel('Average Marks')\n",
        "plt.title('Average Marks for Each Student')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "# Visualize data in a scatter plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(students, averages)\n",
        "plt.xlabel('Student')\n",
        "plt.ylabel('Average Marks')\n",
        "plt.title('Average Marks for Each Student')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "data = {\n",
        "    'Exam seat no': ['3331375', '3331376', '3331377', '3331378', '3331379', '3331380', '3331381', '3331382', '3331383', '3331384', '3331385', '3331386', '3331387', '3331388', '3331389', '3331390', '3331391', '3331392', '3331393', '3331394', '3331395', '3331396', '3331397', '3331398', '3331399'],\n",
        "    'paper 1': [80, 75, 90, 59, 85, 65, 88, 54, 86, 85, 85, 98, 85, 58, 58, 75, 95, 68, 98, 45, 98, 78, 90, 65, 50],\n",
        "    'paper 2': [70, 65, 65, 68, 82, 75, 78, 25, 86, 87, 69, 85, 68, 86, 86, 59, 65, 65, 95, 65, 85, 73, 85, 67, 55],\n",
        "    'paper 3': [75, 87, 75, 75, 88, 73, 98, 65, 75, 64, 78, 84, 78, 47, 65, 45, 75, 67, 97, 54, 86, 74, 92, 62, 64],\n",
        "    'paper 4': [50, 92, 63, 92, 83, 65, 87, 58, 95, 78, 71, 87, 89, 58, 78, 56, 84, 62, 96, 55, 81, 75, 68, 78, 60],\n",
        "    'paper 5': [85, 54, 85, 85, 87, 78, 52, 45, 75, 96, 70, 76, 87, 78, 98, 85, 98, 75, 94, 45, 80, 74, 76, 76, 78]\n",
        "}\n",
        "# Calculate average marks in each subject\n",
        "averages = []\n",
        "for i in range(1, 6):\n",
        "    subject_marks = data['paper ' + str(i)]\n",
        "    average = sum(subject_marks) / len(subject_marks)\n",
        "    averages.append(average)\n",
        "\n",
        "# Visualize the average marks in a bar graph\n",
        "subjects = ['paper 1', 'paper 2', 'paper 3', 'paper 4', 'paper 5']\n",
        "plt.bar(subjects, averages)\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('Average Marks')\n",
        "plt.title('Average Marks in Each Subject')\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "data = {\n",
        "    'Exam seat no': ['3331375', '3331376', '3331377', '3331378', '3331379', '3331380', '3331381', '3331382', '3331383', '3331384', '3331385', '3331386', '3331387', '3331388', '3331389', '3331390', '3331391', '3331392', '3331393', '3331394', '3331395', '3331396', '3331397', '3331398', '3331399'],\n",
        "    'paper 1': [80, 75, 90, 59, 85, 65, 88, 54, 86, 85, 85, 98, 85, 58, 58, 75, 95, 68, 98, 45, 98, 78, 90, 65, 50],\n",
        "    'paper 2': [70, 65, 65, 68, 82, 75, 78, 25, 86, 87, 69, 85, 68, 86, 86, 59, 65, 65, 95, 65, 85, 73, 85, 67, 55],\n",
        "    'paper 3': [75, 87, 75, 75, 88, 73, 98, 65, 75, 64, 78, 84, 78, 47, 65, 45, 75, 67, 97, 54, 86, 74, 92, 62, 64],\n",
        "    'paper 4': [50, 92, 63, 92, 83, 65, 87, 58, 95, 78, 71, 87, 89, 58, 78, 56, 84, 62, 96, 55, 81, 75, 68, 78, 60],\n",
        "    'paper 5': [85, 54, 85, 85, 87, 78, 52, 45, 75, 96, 70, 76, 87, 78, 98, 85, 98, 75, 94, 45, 80, 74, 76, 76, 78]\n",
        "}\n",
        "# Calculate average marks in each subject\n",
        "averages = []\n",
        "for i in range(1, 6):\n",
        "    subject_marks = data['paper ' + str(i)]\n",
        "    average = sum(subject_marks) / len(subject_marks)\n",
        "    averages.append(average)\n",
        "\n",
        "# Visualize the average marks in a scatter diagram\n",
        "plt.scatter(range(1, 6), averages, c='blue', alpha=0.7)\n",
        "plt.xlabel('Subjects')\n",
        "plt.ylabel('Average Marks')\n",
        "plt.title('Average Marks in Each Subject')\n",
        "plt.xticks(range(1, 6))\n",
        "plt.yticks(range(50, 101, 10))\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Box Plot\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data1=([20,25,22,18,16])\n",
        "data2=([32,45,40,46,30])\n",
        "data3=([56,50,45,40,56])\n",
        "data4=([60,56,63,58,66])\n",
        "\n",
        "data=[data1,data2,data3,data4]\n",
        "\n",
        "plt.boxplot(data1)\n",
        "plt.boxplot(data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QNAXbq0EKHKx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
